{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exam_Paper1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Putranto13/Tugas_Machine_Learning/blob/main/FINAL%20Exam/Exam_Paper1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/MnistSimpleCNN-master.zip' #mengambil data yang telah di upload di google colab dan mengekstraknya\n",
        "!unzip MnistSimpleCNN-master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCbyv8uzI_RV",
        "outputId": "9fea26ff-3abf-4f09-ac23-786034c37424"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  MnistSimpleCNN-master.zip\n",
            "3a13cdb79c633c96384318f6c2b634179ce3d191\n",
            "   creating: MnistSimpleCNN-master/\n",
            "  inflating: MnistSimpleCNN-master/README.md  \n",
            "   creating: MnistSimpleCNN-master/code/\n",
            "   creating: MnistSimpleCNN-master/code/__pycache__/\n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/augment.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/ema.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/ema.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/mnist.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/models.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/models.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/transforms.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/transforms.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/datasets.py  \n",
            "  inflating: MnistSimpleCNN-master/code/ema.py  \n",
            "  inflating: MnistSimpleCNN-master/code/ensemble.py  \n",
            "  inflating: MnistSimpleCNN-master/code/homo_ensemble.py  \n",
            "   creating: MnistSimpleCNN-master/code/models/\n",
            "   creating: MnistSimpleCNN-master/code/models/__pycache__/\n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/__init__.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp2.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp3.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/compa1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/hvc.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/hvc.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/merge.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/merge.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modelM5.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela1.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela2.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela2.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela3.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela4.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela4.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modelh.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/models.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/models.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM3.py  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM5.py  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM7.py  \n",
            "   creating: MnistSimpleCNN-master/code/other_models/\n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp1.py  \n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp2.py  \n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp3.py  \n",
            "  inflating: MnistSimpleCNN-master/code/test.py  \n",
            "  inflating: MnistSimpleCNN-master/code/train.py  \n",
            "  inflating: MnistSimpleCNN-master/code/transforms.py  \n",
            "   creating: MnistSimpleCNN-master/data/\n",
            "   creating: MnistSimpleCNN-master/data/MNIST/\n",
            "   creating: MnistSimpleCNN-master/data/MNIST/processed/\n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/processed/test.pt  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/processed/training.pt  \n",
            "   creating: MnistSimpleCNN-master/data/MNIST/raw/\n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte.gz  \n",
            "   creating: MnistSimpleCNN-master/logs/\n",
            " extracting: MnistSimpleCNN-master/logs/README.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]\n",
        "\n"
      ],
      "metadata": {
        "id": "tEy8D44VJU_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mengimport library\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "2Ya3sIf7JbSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torchvision.transforms.functional as W\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return W.rotate(img, angle, False, False, None, None)\n"
      ],
      "metadata": {
        "id": "hsG9BVmUJm2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "lBh6IdiEJrsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "30mDIKcLJ6TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "c87Ja1MaJ8ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimports library\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim #digunakan untuk optimasi\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "#Menjalankan Proses Training\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed \n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size model\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # Nomor Epoch\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    \n",
        "    if not os.path.exists(\"/content/MnistSimpleCNN-master/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/MnistSimpleCNN-master/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/MnistSimpleCNN-master/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    #Menjalankan GPU\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods \n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader \n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # Seleksi Model\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection \n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # Variable global \n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # Pengulangan proses training dan evaluasi \n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Proses Training                                                           #\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "       \n",
        "        # Proses Test                                                             \n",
        "       \n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        # Output                    \n",
        "     \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        \n",
        "        # mengupdate learning rate scheduler                                           \n",
        "        lr_scheduler.step()\n",
        "# seed, epoch, trial, gpu di input secara manual karena pada codingan sebelumnya diambil dari github sehingga tidak bisa dijalankan memakai code sebelumnya\n",
        "\n",
        "#seed untuk menentukan nilai awal\n",
        "p_seed = int(input (\"Seeds: \")) # memasukkan angka sebagai input seed\n",
        "\n",
        "#epoch digunakan untuk melakukan pengulangan (sesuai input) terhadap trial yang dijalankan\n",
        "p_epoch = int(input (\"Epoch: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "#trial digunakan untuk pengulangan percobaan\n",
        "p_trials = int(input (\"Trials: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #memasukkan angka sebagai input epoch (disesuaikan dengan angka pada model)\n",
        "\n",
        "#gpu untuk menjalankan program pada grafik card\n",
        "p_gpu = int(input (\"GPU: \")) #masukkan angka sebagai input GPU\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "\n",
        "#menjalankan GPU\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials): #mengulang percobaan (trial)\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdsRbxW-KD_6",
        "outputId": "1d33db46-c478-451a-fe86-9cc02f046bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 10\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "GPU: 0\n",
            "Logdir: modelM5\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.835055\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.672545\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.446485\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381814\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.333888\n",
            "Best accuracy! correct images:  9892\n",
            "\n",
            "Test set: Average loss: 0.1459, Accuracy: 9892/10000 (98.92%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.322609\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.246928\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257343\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.147037\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.212519\n",
            "\n",
            "Test set: Average loss: 0.1495, Accuracy: 9817/10000 (98.17%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.106649\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.104282\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.138825\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.153324\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.101405\n",
            "Best accuracy! correct images:  9938\n",
            "\n",
            "Test set: Average loss: 0.0524, Accuracy: 9938/10000 (99.38%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.070126\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.088854\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.081230\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.114229\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.107765\n",
            "\n",
            "Test set: Average loss: 0.0491, Accuracy: 9921/10000 (99.21%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.101666\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.060720\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.114014\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.111087\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.067609\n",
            "Best accuracy! correct images:  9950\n",
            "\n",
            "Test set: Average loss: 0.0364, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.151514\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.107427\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.064100\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.056299\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.092642\n",
            "\n",
            "Test set: Average loss: 0.0736, Accuracy: 9856/10000 (98.56%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.082799\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.098478\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.064496\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.066305\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.050288\n",
            "\n",
            "Test set: Average loss: 0.0373, Accuracy: 9941/10000 (99.41%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.105161\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.130052\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.087513\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.039375\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.100055\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.068564\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.024884\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.039851\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.044493\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.040405\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9931/10000 (99.31%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.020310\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.078444\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.027345\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.029373\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.037572\n",
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9947/10000 (99.47%) (best: 99.50%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.773786\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.613684\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.504440\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.368925\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.293218\n",
            "Best accuracy! correct images:  9885\n",
            "\n",
            "Test set: Average loss: 0.1281, Accuracy: 9885/10000 (98.85%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.225022\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.228377\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.178184\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.223749\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.160537\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.1076, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.135640\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.130890\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.089400\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.150468\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.139404\n",
            "Best accuracy! correct images:  9929\n",
            "\n",
            "Test set: Average loss: 0.0589, Accuracy: 9929/10000 (99.29%) (best: 99.29%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.127142\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.140470\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.086391\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091325\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.111024\n",
            "Best accuracy! correct images:  9946\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 9946/10000 (99.46%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.138204\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.062391\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.051429\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.126736\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.108055\n",
            "\n",
            "Test set: Average loss: 0.0545, Accuracy: 9910/10000 (99.10%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.082040\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.052729\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.057406\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.085831\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.102262\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 9937/10000 (99.37%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.132103\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.111938\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.049627\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.105092\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.035924\n",
            "Best accuracy! correct images:  9954\n",
            "\n",
            "Test set: Average loss: 0.0289, Accuracy: 9954/10000 (99.54%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.036588\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.044361\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.073076\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.055444\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.031396\n",
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9932/10000 (99.32%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.072733\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.050246\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.049310\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.068907\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.053737\n",
            "\n",
            "Test set: Average loss: 0.0439, Accuracy: 9903/10000 (99.03%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.082322\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.064633\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.052153\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.036014\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.021966\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9946/10000 (99.46%) (best: 99.54%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.534251\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.655485\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.418252\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.396349\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.302562\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1358, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.275565\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.157069\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.266565\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.225049\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.127945\n",
            "Best accuracy! correct images:  9924\n",
            "\n",
            "Test set: Average loss: 0.0775, Accuracy: 9924/10000 (99.24%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.159125\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.104717\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.133520\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.104508\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.093190\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0463, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.112500\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.108116\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.072373\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.119902\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.096861\n",
            "\n",
            "Test set: Average loss: 0.0607, Accuracy: 9904/10000 (99.04%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.048279\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.062117\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.147288\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.061269\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.075314\n",
            "\n",
            "Test set: Average loss: 0.2292, Accuracy: 9258/10000 (92.58%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.090208\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.062100\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.163507\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.092583\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.050434\n",
            "\n",
            "Test set: Average loss: 0.0320, Accuracy: 9927/10000 (99.27%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.054386\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.083772\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.094434\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.038730\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.057275\n",
            "Best accuracy! correct images:  9946\n",
            "\n",
            "Test set: Average loss: 0.0304, Accuracy: 9946/10000 (99.46%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.021373\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.043372\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.042333\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.056503\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.016980\n",
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 9939/10000 (99.39%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.163931\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.077440\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.086991\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.037188\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.047283\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 9936/10000 (99.36%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.221978\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.048218\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.070188\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.024978\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.067160\n",
            "\n",
            "Test set: Average loss: 0.0254, Accuracy: 9945/10000 (99.45%) (best: 99.46%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.715487\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.598849\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.385839\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.393501\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.222687\n",
            "Best accuracy! correct images:  9877\n",
            "\n",
            "Test set: Average loss: 0.1197, Accuracy: 9877/10000 (98.77%) (best: 98.77%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.250755\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.177847\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.159880\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.119191\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167821\n",
            "Best accuracy! correct images:  9912\n",
            "\n",
            "Test set: Average loss: 0.0726, Accuracy: 9912/10000 (99.12%) (best: 99.12%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.145166\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.159978\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.099546\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.113986\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.166505\n",
            "\n",
            "Test set: Average loss: 0.0725, Accuracy: 9894/10000 (98.94%) (best: 99.12%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.098968\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.100518\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.082005\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.118736\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.103927\n",
            "Best accuracy! correct images:  9928\n",
            "\n",
            "Test set: Average loss: 0.0409, Accuracy: 9928/10000 (99.28%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.078123\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.103936\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.093764\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.065919\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.063685\n",
            "\n",
            "Test set: Average loss: 0.0452, Accuracy: 9908/10000 (99.08%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.050268\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.046732\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.083943\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.074624\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.063223\n",
            "\n",
            "Test set: Average loss: 0.0510, Accuracy: 9916/10000 (99.16%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.079019\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.102871\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.037372\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.061051\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.020808\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0358, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.045934\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.027934\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.106635\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.092039\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.034810\n",
            "Best accuracy! correct images:  9948\n",
            "\n",
            "Test set: Average loss: 0.0249, Accuracy: 9948/10000 (99.48%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.050848\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.055358\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.075419\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.044189\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.026836\n",
            "\n",
            "Test set: Average loss: 0.0323, Accuracy: 9941/10000 (99.41%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.020509\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.029496\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.026565\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.076153\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.065705\n",
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9938/10000 (99.38%) (best: 99.48%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.723286\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.652956\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.526345\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.312364\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.320387\n",
            "Best accuracy! correct images:  9888\n",
            "\n",
            "Test set: Average loss: 0.1417, Accuracy: 9888/10000 (98.88%) (best: 98.88%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.232118\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.219850\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.220962\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.205403\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.205781\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0872, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.116369\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.108751\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.139506\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.132314\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.086242\n",
            "Best accuracy! correct images:  9911\n",
            "\n",
            "Test set: Average loss: 0.0636, Accuracy: 9911/10000 (99.11%) (best: 99.11%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.095974\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.155512\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.086647\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.107343\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.053135\n",
            "Best accuracy! correct images:  9914\n",
            "\n",
            "Test set: Average loss: 0.0519, Accuracy: 9914/10000 (99.14%) (best: 99.14%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.123737\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.124605\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.064446\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.102000\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.053370\n",
            "\n",
            "Test set: Average loss: 0.0706, Accuracy: 9887/10000 (98.87%) (best: 99.14%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.126911\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.101624\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.080826\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.056804\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.074974\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.077253\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.034747\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.070536\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.041714\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.029012\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.064221\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.046486\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.059803\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.074810\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.083895\n",
            "Best accuracy! correct images:  9957\n",
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9957/10000 (99.57%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.078165\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.079921\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.065581\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.076432\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.046388\n",
            "\n",
            "Test set: Average loss: 0.0380, Accuracy: 9906/10000 (99.06%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.087980\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.030419\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.048343\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.062204\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.050743\n",
            "\n",
            "Test set: Average loss: 0.0277, Accuracy: 9940/10000 (99.40%) (best: 99.57%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.751879\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.702585\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.476892\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.338829\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.273951\n",
            "Best accuracy! correct images:  9879\n",
            "\n",
            "Test set: Average loss: 0.1521, Accuracy: 9879/10000 (98.79%) (best: 98.79%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.276195\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.288302\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257404\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.163721\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.157312\n",
            "Best accuracy! correct images:  9927\n",
            "\n",
            "Test set: Average loss: 0.0722, Accuracy: 9927/10000 (99.27%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.145820\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.196976\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.147653\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.089642\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.100429\n",
            "\n",
            "Test set: Average loss: 0.0659, Accuracy: 9923/10000 (99.23%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.104864\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.188275\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.073293\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091839\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.141284\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0564, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.120940\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.073196\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.068399\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.083248\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.111080\n",
            "\n",
            "Test set: Average loss: 0.0504, Accuracy: 9910/10000 (99.10%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.073709\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.079481\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.043734\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.042375\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.110998\n",
            "\n",
            "Test set: Average loss: 0.0383, Accuracy: 9931/10000 (99.31%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.051445\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.050051\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.081705\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.055668\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.051070\n",
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9923/10000 (99.23%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.122927\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.025685\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.046748\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.035008\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.064460\n",
            "\n",
            "Test set: Average loss: 0.0305, Accuracy: 9929/10000 (99.29%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.065223\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.050729\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.047836\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.029951\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.053353\n",
            "\n",
            "Test set: Average loss: 0.1375, Accuracy: 9611/10000 (96.11%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.027072\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.050575\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.020862\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.084489\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.077846\n",
            "Best accuracy! correct images:  9950\n",
            "\n",
            "Test set: Average loss: 0.0218, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.838977\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.657065\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.418213\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.426445\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.310780\n",
            "Best accuracy! correct images:  9887\n",
            "\n",
            "Test set: Average loss: 0.1390, Accuracy: 9887/10000 (98.87%) (best: 98.87%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.292385\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.275872\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.239459\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.183652\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.188473\n",
            "Best accuracy! correct images:  9901\n",
            "\n",
            "Test set: Average loss: 0.0873, Accuracy: 9901/10000 (99.01%) (best: 99.01%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.174594\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.151861\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.137068\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.126698\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.120928\n",
            "Best accuracy! correct images:  9909\n",
            "\n",
            "Test set: Average loss: 0.0788, Accuracy: 9909/10000 (99.09%) (best: 99.09%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.093824\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.121310\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.136414\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.125513\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.112981\n",
            "Best accuracy! correct images:  9924\n",
            "\n",
            "Test set: Average loss: 0.0473, Accuracy: 9924/10000 (99.24%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.092513\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.131419\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.085979\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.077379\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.098227\n",
            "\n",
            "Test set: Average loss: 0.0474, Accuracy: 9912/10000 (99.12%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.075870\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.069749\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.061860\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.052125\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.065027\n",
            "\n",
            "Test set: Average loss: 0.0456, Accuracy: 9922/10000 (99.22%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.039238\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.071818\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.077864\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.050720\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.044725\n",
            "\n",
            "Test set: Average loss: 0.0482, Accuracy: 9903/10000 (99.03%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.039779\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.070517\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.058715\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.037392\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.060847\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.038570\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.030538\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.152990\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.096301\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.036831\n",
            "\n",
            "Test set: Average loss: 0.0268, Accuracy: 9932/10000 (99.32%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.132062\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.038453\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.049231\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.087563\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.061739\n",
            "Best accuracy! correct images:  9948\n",
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9948/10000 (99.48%) (best: 99.48%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.775707\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.630850\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.442278\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.318756\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.291722\n",
            "Best accuracy! correct images:  9881\n",
            "\n",
            "Test set: Average loss: 0.1375, Accuracy: 9881/10000 (98.81%) (best: 98.81%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.285301\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.206047\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.195721\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.233926\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167903\n",
            "Best accuracy! correct images:  9898\n",
            "\n",
            "Test set: Average loss: 0.1079, Accuracy: 9898/10000 (98.98%) (best: 98.98%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.150010\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.146096\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.096876\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.170234\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.111337\n",
            "Best accuracy! correct images:  9905\n",
            "\n",
            "Test set: Average loss: 0.0746, Accuracy: 9905/10000 (99.05%) (best: 99.05%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.142491\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.126919\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.058041\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.074231\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.085478\n",
            "Best accuracy! correct images:  9923\n",
            "\n",
            "Test set: Average loss: 0.0501, Accuracy: 9923/10000 (99.23%) (best: 99.23%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.105417\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.086432\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.076820\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.069151\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.089708\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0410, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.053887\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.057546\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.038212\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.080168\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.088560\n",
            "\n",
            "Test set: Average loss: 0.0383, Accuracy: 9927/10000 (99.27%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.039801\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.062571\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.036811\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.085750\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.046565\n",
            "Best accuracy! correct images:  9938\n",
            "\n",
            "Test set: Average loss: 0.0391, Accuracy: 9938/10000 (99.38%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.047624\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.074899\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.076923\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.039354\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.038655\n",
            "\n",
            "Test set: Average loss: 0.0337, Accuracy: 9937/10000 (99.37%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.059234\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.059842\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.015830\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.073705\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.024357\n",
            "Best accuracy! correct images:  9942\n",
            "\n",
            "Test set: Average loss: 0.0290, Accuracy: 9942/10000 (99.42%) (best: 99.42%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.043820\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.053574\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.059504\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.052990\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.043930\n",
            "Best accuracy! correct images:  9956\n",
            "\n",
            "Test set: Average loss: 0.0241, Accuracy: 9956/10000 (99.56%) (best: 99.56%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.617493\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.657929\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.403715\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.383419\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.309708\n",
            "Best accuracy! correct images:  9864\n",
            "\n",
            "Test set: Average loss: 0.1369, Accuracy: 9864/10000 (98.64%) (best: 98.64%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.260839\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.275594\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.176144\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.182208\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.176965\n",
            "Best accuracy! correct images:  9917\n",
            "\n",
            "Test set: Average loss: 0.0769, Accuracy: 9917/10000 (99.17%) (best: 99.17%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.113312\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.122882\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.119582\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.149775\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.129605\n",
            "Best accuracy! correct images:  9934\n",
            "\n",
            "Test set: Average loss: 0.0520, Accuracy: 9934/10000 (99.34%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.064846\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.094407\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.162755\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.125330\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.163840\n",
            "\n",
            "Test set: Average loss: 0.0822, Accuracy: 9811/10000 (98.11%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.068011\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.083454\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.083778\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.083937\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.062065\n",
            "\n",
            "Test set: Average loss: 0.0572, Accuracy: 9906/10000 (99.06%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.069667\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.086593\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.058116\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.077276\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.069377\n",
            "\n",
            "Test set: Average loss: 0.0536, Accuracy: 9908/10000 (99.08%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.085069\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.090965\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.066764\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.074345\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.068746\n",
            "Best accuracy! correct images:  9941\n",
            "\n",
            "Test set: Average loss: 0.0274, Accuracy: 9941/10000 (99.41%) (best: 99.41%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.060985\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.077690\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.094385\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.047832\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.180808\n",
            "Best accuracy! correct images:  9943\n",
            "\n",
            "Test set: Average loss: 0.0259, Accuracy: 9943/10000 (99.43%) (best: 99.43%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.026147\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.057712\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.085608\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.033759\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.083524\n",
            "\n",
            "Test set: Average loss: 0.0385, Accuracy: 9908/10000 (99.08%) (best: 99.43%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.101157\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.015670\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.041548\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.094011\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.060739\n",
            "\n",
            "Test set: Average loss: 0.0324, Accuracy: 9929/10000 (99.29%) (best: 99.43%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.667550\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.564979\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.479860\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.354094\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.328977\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1449, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.271972\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.253895\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.174983\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.168545\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140008\n",
            "\n",
            "Test set: Average loss: 0.1295, Accuracy: 9793/10000 (97.93%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.112299\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.130382\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.138786\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.069184\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.107866\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.0681, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.203982\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.078670\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.164817\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.049744\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.139097\n",
            "Best accuracy! correct images:  9934\n",
            "\n",
            "Test set: Average loss: 0.0481, Accuracy: 9934/10000 (99.34%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.139653\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.111819\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.058516\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.060666\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.080167\n",
            "\n",
            "Test set: Average loss: 0.0802, Accuracy: 9854/10000 (98.54%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.110907\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.078061\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.078299\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.070836\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.156372\n",
            "\n",
            "Test set: Average loss: 0.0380, Accuracy: 9911/10000 (99.11%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.059380\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.065442\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.090675\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.068886\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.056658\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 9923/10000 (99.23%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.078435\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.040464\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.056042\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.036435\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.106251\n",
            "\n",
            "Test set: Average loss: 0.0316, Accuracy: 9933/10000 (99.33%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.111142\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.038184\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.089358\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.039357\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.038897\n",
            "\n",
            "Test set: Average loss: 0.0427, Accuracy: 9902/10000 (99.02%) (best: 99.34%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.099377\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.034173\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.063197\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.030457\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.045215\n",
            "Best accuracy! correct images:  9965\n",
            "\n",
            "Test set: Average loss: 0.0159, Accuracy: 9965/10000 (99.65%) (best: 99.65%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "YnR-coOSKHkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengimport libary\n",
        "import sys\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "#Running Proses Testing\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data loader \n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection \n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"/content/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,p_seed))) #load data dari drive\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"/content/MnistSimpleCNN-master/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "p_seed = int(input (\"Seeds: \")) # input angka untuk seed\n",
        "p_trials = int(input (\"Trials: \")) # masukkan angka sebagi input berapa kali percobaan\n",
        "p_kernel_size = int (input (\"Kernel size: \")) # masukkan angka sebagai input ukuran kernel (menyesuaikan angka pada model)\n",
        "\n",
        "for y in range (p_trials): #perulangan percobaan (trial)\n",
        "  run(p_seed + y, p_kernel_size, p_logdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF61J6NnKJpO",
        "outputId": "09a114d4-4f9f-44db-a855-550ba8c31cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logdir: modelM5\n",
            "Seeds: 0\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "50 [193, 449, 582, 625, 938, 1226, 1232, 1403, 1901, 2035, 2040, 2130, 2135, 2293, 2326, 2447, 2462, 2488, 2534, 2597, 3073, 3225, 3534, 3558, 3762, 3906, 4018, 4065, 4201, 4740, 4761, 4823, 5457, 5955, 6558, 6576, 6597, 6783, 6883, 7216, 8316, 8325, 8387, 8408, 8527, 9009, 9024, 9729, 9754, 9850]\n",
            "46 [449, 582, 625, 646, 659, 882, 938, 947, 1226, 1232, 1260, 1459, 1621, 1901, 2040, 2130, 2293, 2462, 2488, 2597, 3225, 3422, 3558, 3762, 3985, 4018, 4176, 4369, 4497, 4740, 4761, 4823, 4860, 5955, 6554, 6576, 6625, 7216, 8275, 8279, 8408, 8527, 9664, 9700, 9729, 9749]\n",
            "54 [445, 447, 625, 938, 947, 1014, 1050, 1226, 1232, 1737, 1901, 2035, 2040, 2098, 2118, 2130, 2293, 2454, 2462, 2488, 2597, 2654, 2939, 2959, 3030, 3073, 3225, 3330, 3384, 3422, 3558, 3762, 3846, 3853, 4201, 4443, 4547, 4620, 4740, 4761, 4814, 4860, 5457, 5937, 6554, 6576, 6625, 7216, 8065, 8279, 8408, 8527, 9700, 9729]\n",
            "52 [321, 445, 447, 582, 659, 938, 947, 1050, 1112, 1232, 1299, 1737, 1901, 2035, 2040, 2098, 2118, 2130, 2148, 2447, 2462, 2488, 2597, 2654, 2939, 3225, 3384, 3422, 3558, 3762, 3846, 4018, 4176, 4547, 4740, 4761, 4783, 4860, 5888, 5936, 5955, 6576, 6625, 7216, 8275, 8279, 8408, 8527, 9664, 9729, 9754, 9792]\n",
            "43 [445, 447, 449, 582, 938, 1226, 1232, 1260, 1403, 1709, 1901, 2040, 2118, 2130, 2454, 2462, 2597, 2771, 3030, 3225, 3422, 3534, 3558, 3762, 4018, 4201, 4443, 4740, 4814, 4823, 4860, 5654, 5937, 5955, 6576, 6625, 8408, 8527, 9009, 9669, 9729, 9754, 9792]\n",
            "50 [359, 445, 582, 625, 659, 674, 947, 1232, 1260, 1299, 1737, 1901, 1911, 2035, 2040, 2118, 2130, 2135, 2293, 2414, 2454, 2462, 2597, 3030, 3369, 3384, 3422, 3558, 3985, 4018, 4201, 4443, 4547, 4620, 4761, 4823, 5937, 5955, 5997, 6571, 6576, 6625, 8275, 8279, 8408, 9664, 9700, 9729, 9749, 9754]\n",
            "52 [41, 193, 247, 447, 468, 582, 674, 726, 1039, 1226, 1232, 1260, 1393, 1737, 1901, 1903, 2035, 2040, 2130, 2293, 2414, 2462, 2597, 3189, 3225, 3422, 3534, 3558, 3762, 3808, 4027, 4761, 4860, 5654, 5745, 5937, 5955, 6558, 6576, 6599, 6625, 7216, 8316, 8325, 8408, 8527, 9009, 9024, 9505, 9679, 9729, 9754]\n",
            "44 [447, 449, 726, 938, 1039, 1112, 1232, 1621, 1901, 2035, 2040, 2098, 2130, 2447, 2462, 2488, 2597, 2654, 2771, 2939, 3225, 3534, 3726, 3762, 4018, 4053, 4065, 4443, 4551, 4740, 4860, 5937, 5955, 6561, 6576, 6625, 7216, 8095, 8408, 8527, 9664, 9679, 9729, 9754]\n",
            "57 [447, 582, 625, 674, 1039, 1226, 1232, 1260, 1299, 1393, 1459, 1716, 1737, 1901, 2035, 2040, 2118, 2130, 2135, 2293, 2454, 2462, 2597, 2654, 2939, 2959, 2995, 3225, 3384, 3422, 3534, 3558, 3762, 3846, 4176, 4443, 4497, 4547, 4620, 4860, 5654, 5745, 5937, 6558, 6576, 6599, 6625, 8095, 8275, 8408, 8527, 9009, 9669, 9679, 9729, 9749, 9754]\n",
            "35 [445, 447, 625, 674, 938, 1232, 1621, 1901, 2035, 2040, 2130, 2293, 2454, 2462, 2488, 2597, 3225, 3422, 3534, 3558, 3762, 4176, 4201, 4571, 4860, 5955, 6576, 6625, 8094, 8325, 8408, 8527, 9009, 9693, 9729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOMO ENSEMBLE"
      ],
      "metadata": {
        "id": "MEcH_DrrKLXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mengimport libary\n",
        "import numpy as np \n",
        "import argparse\n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input ukuran kernel \n",
        "\n",
        "KERNEL_SIZE = p_kernel_size \n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(i+1,10):\n",
        "        for k in range(j+1,10):\n",
        "            w1 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPfhuidbKOSw",
        "outputId": "271e916a-7b28-4857-d972-62e019a78aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel size: 5\n",
            "   1   50   46   54   37   37\n",
            "   2   50   46   52   38   37\n",
            "   3   50   46   43   35   35\n",
            "   4   50   46   50   41   35\n",
            "   5   50   46   52   39   35\n",
            "   6   50   46   44   35   35\n",
            "   7   50   46   57   41   35\n",
            "   8   50   46   35   36   35\n",
            "   9   50   54   52   46   35\n",
            "  10   50   54   43   45   35\n",
            "  11   50   54   50   46   35\n",
            "  12   50   54   52   41   35\n",
            "  13   50   54   44   40   35\n",
            "  14   50   54   57   47   35\n",
            "  15   50   54   35   35   35\n",
            "  16   50   52   43   38   35\n",
            "  17   50   52   50   42   35\n",
            "  18   50   52   52   38   35\n",
            "  19   50   52   44   35   35\n",
            "  20   50   52   57   45   35\n",
            "  21   50   52   35   36   35\n",
            "  22   50   43   50   40   35\n",
            "  23   50   43   52   42   35\n",
            "  24   50   43   44   37   35\n",
            "  25   50   43   57   42   35\n",
            "  26   50   43   35   37   35\n",
            "  27   50   50   52   40   35\n",
            "  28   50   50   44   36   35\n",
            "  29   50   50   57   43   35\n",
            "  30   50   50   35   34   34\n",
            "  31   50   52   44   42   34\n",
            "  32   50   52   57   44   34\n",
            "  33   50   52   35   37   34\n",
            "  34   50   44   57   42   34\n",
            "  35   50   44   35   34   34\n",
            "  36   50   57   35   35   34\n",
            "  37   46   54   52   47   34\n",
            "  38   46   54   43   43   34\n",
            "  39   46   54   50   50   34\n",
            "  40   46   54   52   35   34\n",
            "  41   46   54   44   40   34\n",
            "  42   46   54   57   49   34\n",
            "  43   46   54   35   36   34\n",
            "  44   46   52   43   39   34\n",
            "  45   46   52   50   45   34\n",
            "  46   46   52   52   37   34\n",
            "  47   46   52   44   40   34\n",
            "  48   46   52   57   48   34\n",
            "  49   46   52   35   36   34\n",
            "  50   46   43   50   44   34\n",
            "  51   46   43   52   34   34\n",
            "  52   46   43   44   35   34\n",
            "  53   46   43   57   42   34\n",
            "  54   46   43   35   36   34\n",
            "  55   46   50   52   40   34\n",
            "  56   46   50   44   42   34\n",
            "  57   46   50   57   49   34\n",
            "  58   46   50   35   41   34\n",
            "  59   46   52   44   38   34\n",
            "  60   46   52   57   44   34\n",
            "  61   46   52   35   34   34\n",
            "  62   46   44   57   46   34\n",
            "  63   46   44   35   31   31\n",
            "  64   46   57   35   36   31\n",
            "  65   54   52   43   47   31\n",
            "  66   54   52   50   52   31\n",
            "  67   54   52   52   41   31\n",
            "  68   54   52   44   43   31\n",
            "  69   54   52   57   48   31\n",
            "  70   54   52   35   41   31\n",
            "  71   54   43   50   45   31\n",
            "  72   54   43   52   40   31\n",
            "  73   54   43   44   40   31\n",
            "  74   54   43   57   46   31\n",
            "  75   54   43   35   35   31\n",
            "  76   54   50   52   43   31\n",
            "  77   54   50   44   46   31\n",
            "  78   54   50   57   48   31\n",
            "  79   54   50   35   39   31\n",
            "  80   54   52   44   37   31\n",
            "  81   54   52   57   48   31\n",
            "  82   54   52   35   35   31\n",
            "  83   54   44   57   43   31\n",
            "  84   54   44   35   35   31\n",
            "  85   54   57   35   41   31\n",
            "  86   52   43   50   44   31\n",
            "  87   52   43   52   36   31\n",
            "  88   52   43   44   40   31\n",
            "  89   52   43   57   45   31\n",
            "  90   52   43   35   33   31\n",
            "  91   52   50   52   40   31\n",
            "  92   52   50   44   45   31\n",
            "  93   52   50   57   48   31\n",
            "  94   52   50   35   42   31\n",
            "  95   52   52   44   39   31\n",
            "  96   52   52   57   47   31\n",
            "  97   52   52   35   33   31\n",
            "  98   52   44   57   46   31\n",
            "  99   52   44   35   35   31\n",
            " 100   52   57   35   40   31\n",
            " 101   43   50   52   40   31\n",
            " 102   43   50   44   37   31\n",
            " 103   43   50   57   47   31\n",
            " 104   43   50   35   37   31\n",
            " 105   43   52   44   37   31\n",
            " 106   43   52   57   40   31\n",
            " 107   43   52   35   34   31\n",
            " 108   43   44   57   41   31\n",
            " 109   43   44   35   34   31\n",
            " 110   43   57   35   38   31\n",
            " 111   50   52   44   36   31\n",
            " 112   50   52   57   49   31\n",
            " 113   50   52   35   35   31\n",
            " 114   50   44   57   45   31\n",
            " 115   50   44   35   34   31\n",
            " 116   50   57   35   42   31\n",
            " 117   52   44   57   42   31\n",
            " 118   52   44   35   33   31\n",
            " 119   52   57   35   40   31\n",
            " 120   44   57   35   37   31\n"
          ]
        }
      ]
    }
  ]
}